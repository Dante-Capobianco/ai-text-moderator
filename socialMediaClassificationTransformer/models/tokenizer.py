#Tokenize text input (given an input set of data based on training/trainer.py)
#Put results of different methods (different ways of handling padding, truncation, long sequences) & distribution of token lenghts in Jupyter notebook & adjust maximum sequence lengths

#use BPE or wordpiece tokenization possibly